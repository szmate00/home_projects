{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: style loss nem biztos jó, lehet le kell osztani az MSE-t\n",
    "# TODO: eredmény megjelenítésre függvény"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as tf\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get feature maps from VGG\n",
    "def get_features(image, model, layers):\n",
    "    features = {}\n",
    "\n",
    "    x = image\n",
    "    for name, number in model._modules.items():\n",
    "        x = number(x)\n",
    "\n",
    "        if name in layers:\n",
    "            features[layers[name]] = x\n",
    "            \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transform\n",
    "# source: https://github.com/Shashi456/Neural-Style/blob/master/Neural%20Style%20Transfer/train_Pytorch.py\n",
    "transform = tf.Compose([\n",
    "    tf.Resize(512),\n",
    "    tf.ToTensor(),\n",
    "    tf.Lambda(lambda x:x[torch.LongTensor([2, 1,0])]),\n",
    "    tf.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], std=[0.225, 0.224, 0.229]),\n",
    "    tf.Lambda(lambda x: x.mul_(255))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for image loading and transforming\n",
    "def img_load(path):\n",
    "    img = Image.open(path)\n",
    "    img = Variable(transform(img))\n",
    "    img = img.unsqueeze(0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating gram matrix of feature map\n",
    "def gram_matrix(input):\n",
    "    '''\n",
    "    Gram matrix should have shape of K * N, where K is the number of feature maps at the given layer,\n",
    "    N is the length of the vector after transforming the 2D feature map to 1D vector.\n",
    "    N = a * b if one feature map has a shape of a * b.\n",
    "    So input has a shape of K * a * b\n",
    "    '''\n",
    "    batch_size, K, a, b = input.size()\n",
    "    vecs = input.view(K, a * b)\n",
    "\n",
    "    # definition of Gram matrix\n",
    "    gram = vecs @ vecs.T\n",
    "\n",
    "    # returning normalized matrix\n",
    "    return gram / (K * a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained VGG\n",
    "vgg = models.vgg19(pretrained=True).features\n",
    "\n",
    "# freezing weights\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images\n",
    "content = img_load('content.png').to(device)\n",
    "style = img_load('style.png').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using original content image to use style transfer on\n",
    "x = content.clone().requires_grad_(True).to(device)\n",
    "\n",
    "# using Adam to optimize our image\n",
    "optimizer = optim.Adam([x], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers to caclulate stlye and content losses with (see 3rd cell)\n",
    "layers = {'0': 'conv1_1',\n",
    "            '5':  'conv2_1',\n",
    "            '10': 'conv3_1',\n",
    "            '19': 'conv4_1',\n",
    "            '21': 'conv4_2',\n",
    "            '28': 'conv5_1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target content feature map\n",
    "content_features = get_features(content, vgg, layers)\n",
    "\n",
    "style_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "\n",
    "# calculating gram matrices of each style layer to use as targets\n",
    "style_grams = {layer: gram_matrix(content_features[layer]) for layer in style_layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "EPOCHS = 100\n",
    "content_weight = 1\n",
    "style_weight = 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # content loss\n",
    "    x_features = get_features(x, vgg, layers)\n",
    "    content_loss = F.mse_loss(x_features[\"conv4_2\"], content_features[\"conv4_2\"])\n",
    "\n",
    "    # style loss\n",
    "    # summing up the losses from each style layer\n",
    "    style_loss = 0\n",
    "    for layer in style_layers:\n",
    "        x_style = x_features[layer]\n",
    "        style_loss += F.mse_loss(gram_matrix(x_style), style_grams[layer])\n",
    "\n",
    "    # total loss is content loss + style loss with weights as seen in the paper\n",
    "    total_loss = content_weight * content_loss + style_weight * style_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch: %d | Total Loss: %.5f' % (epoch + 1, total_loss.item()))\n",
    "\n",
    "print('-----------------------------')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}